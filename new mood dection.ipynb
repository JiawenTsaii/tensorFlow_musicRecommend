{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5098abd8-3eaf-4793-a1b2-3a4e523857ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "# 加載已保存的模型\n",
    "model = load_model('model_new_training_optimal.h5', compile=False)\n",
    "\n",
    "def emotion_recog(frame):\n",
    "    emotions = []\n",
    "\n",
    "    # 防止使用 OpenCL 及不必要的日誌訊息\n",
    "    cv2.ocl.setUseOpenCL(False)\n",
    "\n",
    "    # 將每個標籤分配給情緒的字典\n",
    "    emotion_dict = {0: \"Angry\", 1: \"Happy\", 2: \"Sad\", 3: \"Calm\"}\n",
    "\n",
    "    # 加載人臉檢測分類器\n",
    "    facecasc = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    if facecasc.empty():\n",
    "        raise IOError('Could not load haarcascade_frontalface_default.xml')\n",
    "\n",
    "    # 將圖像轉換為灰度圖\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = facecasc.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=2)\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(frame, (x, y-50), (x+w, y+h+10), (255, 0, 255), 3)\n",
    "        roi_gray = gray[y:y + h, x:x + w]\n",
    "        cropped_img = np.expand_dims(np.expand_dims(cv2.resize(roi_gray, (48, 48)), -1), 0)\n",
    "        prediction = model.predict(cropped_img)\n",
    "        maxindex = int(np.argmax(prediction))\n",
    "        emotion_label = emotion_dict[maxindex]\n",
    "        cv2.putText(frame, emotion_label, (x+20, y-60), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "        emotions.append(emotion_label)\n",
    "\n",
    "        plt.figure()\n",
    "        plt.imshow(cv2.cvtColor(cv2.resize(frame[y:y + h, x:x + w], (48, 48)), cv2.COLOR_BGR2RGB))\n",
    "        plt.title(emotion_label)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "        \n",
    "        # 只處理第一個檢測到的臉部\n",
    "        break\n",
    "\n",
    "    return frame, emotions\n",
    "\n",
    "def display_image(image):\n",
    "    \"\"\"使用 matplotlib 顯示圖像。\"\"\"\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(image_rgb)\n",
    "    plt.axis('on')\n",
    "    plt.show()\n",
    "\n",
    "# 從文件系統讀取圖像\n",
    "input_image = cv2.imread('sad face.jpg')\n",
    "\n",
    "# 執行情緒識別\n",
    "output_image, predicted_emotions = emotion_recog(input_image)\n",
    "print(\"predicted output:\", predicted_emotions)\n",
    "final_emotion = predicted_emotions\n",
    "\n",
    "# 顯示結果\n",
    "print(\"原圖\")\n",
    "display_image(output_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1980924",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"Gaussian_Mixture_Models.ipynb\n",
    "\n",
    "Automatically generated by Colab.\n",
    "\n",
    "Original file is located at\n",
    "    https://colab.research.google.com/drive/1ABJQ3FQEiI5NQFUH5S2dlHSUKBcMvnYp\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('genres_v2.csv')\n",
    "df.head()\n",
    "\n",
    "df[df['song_name'].isnull()]\n",
    "\n",
    "#dropping rows with no song names and no uri and then dropping duplicates as well\n",
    "\n",
    "# Drop rows with no song names and no URI\n",
    "df = df.dropna(subset=['song_name', 'uri'])\n",
    "\n",
    "# Remove duplicate rows based on 'song_name' and 'uri'\n",
    "df = df.drop_duplicates(subset=['song_name', 'uri'])\n",
    "\n",
    "# Get the count of final rows\n",
    "final_row_count = len(df)\n",
    "\n",
    "print(\"Count of final rows:\", final_row_count)\n",
    "\n",
    "cols = ['danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness',\n",
    "       'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo','uri','genre','song_name']\n",
    "filtered_df = df[cols]\n",
    "filtered_df\n",
    "\n",
    "# 加载数据\n",
    "# 假设 filtered_df 已经定义并包含了数据\n",
    "num_cols = [i for i in filtered_df.columns if filtered_df[i].dtype != 'object']\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# 使用 .loc 方法进行赋值\n",
    "filtered_df.loc[:, num_cols] = scaler.fit_transform(filtered_df[num_cols])\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "n_components = 2 # 或者 3 进行3D可视化\n",
    "pca = PCA(n_components=n_components)\n",
    "pca_result = pca.fit_transform(filtered_df[num_cols])\n",
    "pca_df = pd.DataFrame(pca_result, columns=[f'PC{i+1}' for i in range(n_components)])\n",
    "\n",
    "n_clusters = 4  # 假设有4个聚类\n",
    "gmm = GaussianMixture(n_components=n_clusters, random_state=42)\n",
    "pca_df['cluster'] = gmm.fit_predict(pca_result)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.scatterplot(x=pca_result[:, 0], y=pca_result[:, 1], hue=pca_df['cluster'], palette='viridis', s=50)\n",
    "plt.title(f'PCA Results with GMM Clustering with {n_clusters} clusters')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "\n",
    "# 绘制每个簇的中心点\n",
    "centers = gmm.means_\n",
    "plt.scatter(centers[:, 0], centers[:, 1], c='red', s=200, marker='X', edgecolors='black', label='Centers')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# 计算每个簇的均值向量\n",
    "cluster_means = pca_df.groupby('cluster').mean().values\n",
    "\n",
    "# 计算不同簇之间的余弦相似度\n",
    "inter_cluster_cosine_sim = cosine_similarity(cluster_means)\n",
    "\n",
    "# 打印不同簇之间的余弦相似度矩阵\n",
    "print(\"Inter-cluster cosine similarity matrix:\")\n",
    "sns.heatmap(pd.DataFrame(inter_cluster_cosine_sim, index=np.unique(pca_df['cluster']), columns=np.unique(pca_df['cluster'])), cmap='viridis', annot=True, fmt=\".2f\", annot_kws={\"size\": 14})\n",
    "\n",
    "# 可视化不同簇之间的余弦相似度矩阵\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(pd.DataFrame(inter_cluster_cosine_sim, index=np.unique(pca_df['cluster']), columns=np.unique(pca_df['cluster'])), cmap='viridis', annot=True)\n",
    "plt.title('Cosine Similarity Matrix Between Clusters')\n",
    "plt.show()\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# 假设 filtered_df 已经定义并包含了数据\n",
    "num_cols = [i for i in filtered_df.columns if filtered_df[i].dtype != 'object']\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# 使用 .loc 方法进行赋值\n",
    "filtered_df.loc[:, num_cols] = scaler.fit_transform(filtered_df[num_cols])\n",
    "\n",
    "# 进行 PCA\n",
    "n_components = 3  # 调整主成分数量\n",
    "pca = PCA(n_components=n_components)\n",
    "pca_result = pca.fit_transform(filtered_df[num_cols])\n",
    "pca_df = pd.DataFrame(pca_result, columns=[f'PC{i+1}' for i in range(n_components)])\n",
    "\n",
    "# 进行 GMM 分群\n",
    "n_clusters = 4  # 调整簇数量\n",
    "gmm = GaussianMixture(n_components=n_clusters, random_state=42)\n",
    "pca_df['cluster'] = gmm.fit_predict(pca_result)\n",
    "\n",
    "# 可视化 PCA 3D 结果\n",
    "fig = plt.figure(figsize=(12, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# 绘制散点图\n",
    "scatter = ax.scatter(pca_result[:, 0], pca_result[:, 1], pca_result[:, 2], c=pca_df['cluster'], cmap='viridis', s=50)\n",
    "\n",
    "# 添加每个簇的中心点\n",
    "centers = gmm.means_\n",
    "ax.scatter(centers[:, 0], centers[:, 1], centers[:, 2], c='red', s=200, marker='X', edgecolors='black', label='Centers')\n",
    "\n",
    "# 添加图例和标签\n",
    "legend1 = ax.legend(*scatter.legend_elements(), title=\"Clusters\")\n",
    "ax.add_artist(legend1)\n",
    "ax.set_title(f'PCA Results with GMM Clustering with {n_clusters} clusters')\n",
    "ax.set_xlabel('Principal Component 1')\n",
    "ax.set_ylabel('Principal Component 2')\n",
    "ax.set_zlabel('Principal Component 3')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# 假设 filtered_df 已经定义并包含了数据\n",
    "num_cols = [i for i in filtered_df.columns if filtered_df[i].dtype != 'object']\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# 使用 .loc 方法进行赋值\n",
    "filtered_df.loc[:, num_cols] = scaler.fit_transform(filtered_df[num_cols])\n",
    "\n",
    "# 进行 PCA\n",
    "n_components = 3  # 调整主成分数量\n",
    "pca = PCA(n_components=n_components)\n",
    "pca_result = pca.fit_transform(filtered_df[num_cols])\n",
    "pca_df = pd.DataFrame(pca_result, columns=[f'PC{i+1}' for i in range(n_components)])\n",
    "\n",
    "# 进行 GMM 分群\n",
    "n_clusters = 4  # 调整簇数量\n",
    "gmm = GaussianMixture(n_components=n_clusters, random_state=42)\n",
    "pca_df['cluster'] = gmm.fit_predict(pca_result)\n",
    "\n",
    "# 绘制3D PCA结果\n",
    "fig = px.scatter_3d(\n",
    "    pca_df, x='PC1', y='PC2', z='PC3',\n",
    "    color='cluster',\n",
    "    title='PCA Results with GMM Clustering',\n",
    "    labels={'PC1': 'Principal Component 1', 'PC2': 'Principal Component 2', 'PC3': 'Principal Component 3'},\n",
    "    opacity=0.7  # 使点稍微透明，以便更好地观察\n",
    ")\n",
    "\n",
    "# 添加每个簇的中心点\n",
    "centers = gmm.means_\n",
    "center_df = pd.DataFrame(centers, columns=['PC1', 'PC2', 'PC3'])\n",
    "\n",
    "# 使用不同的方式添加簇中心点，增强可视化效果\n",
    "fig.add_trace(go.Scatter3d(\n",
    "    x=center_df['PC1'], y=center_df['PC2'], z=center_df['PC3'],\n",
    "    mode='markers',\n",
    "    marker=dict(size=10, color='red', symbol='x'),\n",
    "    name='Cluster Centers'\n",
    "))\n",
    "\n",
    "# 更新图表布局以增加图的尺寸\n",
    "fig.update_layout(\n",
    "    width=1000,  # 图的宽度\n",
    "    height=800,  # 图的高度\n",
    "    scene=dict(\n",
    "        xaxis_title='Principal Component 1',\n",
    "        yaxis_title='Principal Component 2',\n",
    "        zaxis_title='Principal Component 3'\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21fa9124-7ec6-4fa7-a6e4-2672fd7e8463",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# 打開攝像頭\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# 讀取一幀\n",
    "ret, frame = cap.read()\n",
    "if not ret:\n",
    "    print(\"Failed to capture image\")\n",
    "    cap.release()\n",
    "    exit()\n",
    "\n",
    "# 獲取幀的高度和寬度\n",
    "frame_height, frame_width, _ = frame.shape\n",
    "\n",
    "# 創建VideoWriter對象，定義視頻編碼和輸出文件名\n",
    "out = cv2.VideoWriter('output.avi', cv2.VideoWriter_fourcc('M', 'J', 'P', 'G'), 10, (frame_width, frame_height))\n",
    "\n",
    "print(\"Processing Video...\")\n",
    "\n",
    "# 執行情緒識別\n",
    "output_frame, predicted_emotions = emotion_recog(frame)\n",
    "\n",
    "# 檢查output_frame的類型和形狀，確保格式正確\n",
    "print(type(output_frame), output_frame.shape)\n",
    "print(\"Predicted Emotions:\", predicted_emotions)\n",
    "\n",
    "if predicted_emotions == ['Happy']:\n",
    "    final_emotion = 'Happy'\n",
    "elif predicted_emotions == ['Angry']:\n",
    "    final_emotion = 'Calm'\n",
    "elif predicted_emotions == ['Calm']:\n",
    "    final_emotion = 'Angry'\n",
    "elif predicted_emotions == ['Sad']:\n",
    "    final_emotion = 'Sad'\n",
    "\n",
    "# 寫入幀到文件\n",
    "out.write(output_frame)\n",
    "\n",
    "# 釋放資源\n",
    "out.release()\n",
    "cap.release()\n",
    "\n",
    "# 顯示結果\n",
    "def display_image(image):\n",
    "    \"\"\"使用 matplotlib 顯示圖像。\"\"\"\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(image_rgb)\n",
    "    plt.axis('on')\n",
    "    plt.show()\n",
    "\n",
    "display_image(output_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d169d46-75d8-4c2d-80ed-005c73849d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca_df的結果加上情緒標籤\n",
    "pca_df['mood'] = np.random.choice(['Sad', 'Calm', 'Angry', 'Happy'], len(pca_df))\n",
    "\n",
    "# 先存到final_df後再做處理(把song_name放回去、刪掉song_name是NaN的資料)\n",
    "final_df = pd.concat([df[['song_name', 'uri']], pca_df], axis=1)\n",
    "# 删除 song_name 是 NaN 的行\n",
    "final_df = final_df.dropna(subset=['song_name'])\n",
    "\n",
    "\n",
    "\n",
    "# detected_mood = input(\"input（Sad, Calm, Angry, Happy）: \")\n",
    "detected_mood = final_emotion\n",
    "# print(final_emotion)\n",
    "valid_moods = ['Sad', 'Calm', 'Angry', 'Happy']\n",
    "\n",
    "\n",
    "if detected_mood not in valid_moods:\n",
    "    print(\"not found please input：Sad or Calm or Angry or Happy\")\n",
    "else:\n",
    "    filtered_by_mood = final_df[final_df['mood'] == detected_mood]\n",
    "    if filtered_by_mood.empty:\n",
    "        print(f\"not found any song with {detected_mood} emotion。\")\n",
    "    else:\n",
    "        from selenium import webdriver\n",
    "        from selenium.webdriver.common.keys import Keys\n",
    "        from selenium.webdriver.common.by import By\n",
    "        from selenium.webdriver.chrome.service import Service\n",
    "        from selenium.webdriver.chrome.options import Options\n",
    "        from selenium.webdriver.support.ui import WebDriverWait\n",
    "        from selenium.webdriver.support import expected_conditions as EC    \n",
    "        import time\n",
    "        import os\n",
    "        random_songs = filtered_by_mood.sample(3)['song_name']\n",
    "        print(\"random song with\", detected_mood, \"emotion is: \")\n",
    "        print(random_songs.to_list())\n",
    "\n",
    "        songs = [{\"song_name\": song_name} for song_name in random_songs]\n",
    "\n",
    "        # chrome初始設定\n",
    "        chrome_options = Options()\n",
    "        chrome_options.add_argument(\"--start-maximized\")\n",
    "        chrome_options.add_argument(\"--disable-infobars\")\n",
    "        chrome_options.add_argument(\"--disable-extensions\")\n",
    "        chrome_driver_path = os.path.join('chromedriver.exe')\n",
    "\n",
    "\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "\n",
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "\n",
    "# try:\n",
    "from selenium import webdriver\n",
    "for song in songs:\n",
    "    song_name = song['song_name']\n",
    "    driver.get(\"https://www.youtube.com\")\n",
    "    time.sleep(2) \n",
    "\n",
    "    # 搜尋\n",
    "    search_box = driver.find_element(By.NAME, \"search_query\")\n",
    "    search_box.send_keys(song_name)\n",
    "    search_box.send_keys(Keys.RETURN)\n",
    "    time.sleep(2) \n",
    "    WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.ID, \"video-title\")))\n",
    "\n",
    "    # 選第二個影片(第一個太常是廣告了 可惡)\n",
    "    search_results = driver.find_elements(By.ID, \"video-title\")\n",
    "    second_video = search_results[1]\n",
    "    second_video.click()\n",
    "\n",
    "    time.sleep(5) \n",
    "\n",
    "    # 影片播的時長\n",
    "    time.sleep(30) # 30sec\n",
    "\n",
    "# finally:\n",
    "    time.sleep(5)\n",
    "    driver.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
